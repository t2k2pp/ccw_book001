# 第11章: ローカル生成AI（画像生成）

## 11.1 ローカル画像生成AIの概要とメリット

### ローカル実行の利点

**プライバシーとセキュリティ**
- 画像データがローカル環境に留まり、外部サーバーに送信されない
- 企業秘密や個人情報を含むビジュアルコンテンツの安全な生成
- NSFWコンテンツなど、クラウドサービスで制限される内容の自由な生成

**コストメリット**
- 初期投資後は無制限に画像生成が可能
- クラウドサービス（Midjourney Pro: $60/月、DALL-E 3: $0.04-0.08/枚）と比較して長期的にコスト削減
- 大量の画像生成が必要な場合に特に有利

**カスタマイズ性**
- ファインチューニングにより特定のスタイルやキャラクターを学習可能
- LoRA（Low-Rank Adaptation）による軽量なモデル拡張
- ControlNetによる構図の詳細な制御

**生成速度とオフライン動作**
- ローカルGPUによる高速生成（RTX 4090で数秒）
- インターネット接続不要で安定動作
- バッチ処理による大量画像の効率的な生成

### 主な用途

- イラスト制作・コンセプトアート
- ゲーム開発用アセット生成
- マーケティング素材の作成
- 建築・インテリアデザインの可視化
- ファッションデザインのモックアップ
- 写真のスタイル変換・編集

---

## 11.2 マシンスペック別推奨モデル

### 最小構成（VRAM 6-8GB）

**推奨GPU**: GTX 1660 Ti (6GB)、RTX 3060 (8GB)、RTX 4060 (8GB)

**対応モデル**:
- Stable Diffusion 1.5/2.1（512×512）
- SDXL Turbo（高速生成、最適化あり）

**制限事項**:
- 高解像度（1024×1024以上）は困難
- バッチ処理は小サイズのみ
- 一部の拡張機能（ControlNet複数同時利用など）は制限あり

### 標準構成（VRAM 10-12GB）

**推奨GPU**: RTX 3060 12GB、RTX 3080 (10-12GB)、RTX 4060 Ti (16GB)

**対応モデル**:
- Stable Diffusion XL（1024×1024）
- FLUX.1 Schnell（量子化版、高速生成）
- Stable Diffusion 1.5/2.1（高解像度、複数ControlNet）

**推奨用途**:
- 一般的なイラスト・写真生成
- ControlNetを使った構図制御
- img2img、inpainting

### 推奨構成（VRAM 16-24GB）

**推奨GPU**: RTX 4080 (16GB)、RTX 4090 (24GB)、RTX A5000 (24GB)

**対応モデル**:
- FLUX.1 Dev（FP16完全版）
- Stable Diffusion XL（複数拡張機能同時使用）
- カスタムファインチューニングモデル

**推奨用途**:
- プロフェッショナルなイラスト制作
- 高解像度画像生成（2048×2048以上）
- 複雑なワークフロー（複数ControlNet + LoRA）
- モデルのファインチューニング

### ハイエンド構成（VRAM 40GB+）

**推奨GPU**: RTX A6000 (48GB)、A100 (40-80GB)、H100 (80GB)

**対応モデル**:
- FLUX.1 Pro相当のカスタムモデル
- 複数モデルの同時実行
- 超高解像度生成（4K以上）

**推奨用途**:
- モデル開発・研究
- 商用大規模バッチ処理
- マルチモデル並列実行

---

## 11.3 画像生成モデルカタログ（2025年版）

### ⭐ FLUX.1（最推奨 - 最高品質）

**開発**: Black Forest Labs（元Stable Diffusion開発チーム）
**リリース**: 2024年8月

**バリエーション**:

| モデル | パラメータ | VRAM要件 | 速度 | ライセンス | 品質スコア |
|--------|------------|----------|------|------------|------------|
| FLUX.1 Schnell | 12B | 6-8GB (量子化) | 超高速（1-4ステップ） | Apache 2.0 | ⭐⭐⭐⭐ |
| FLUX.1 Dev | 12B | 16-24GB (FP16) | 中速（20-30ステップ） | 非商用 | ⭐⭐⭐⭐⭐ |
| FLUX.1 Pro | 12B | API提供のみ | 高速 | 商用 | ⭐⭐⭐⭐⭐ |

**主な特徴**:
- テキストレンダリング精度が最高レベル（画像内の文字を正確に生成）
- プロンプト遵守性が非常に高い
- 人体解剖学の正確性（手・指の描写が自然）
- 複雑なシーンや構図の忠実な再現

**ベンチマーク**: FLUX.1 Devは品質スコア94.6%を記録（2025年テスト）

**推奨用途**:
- ポスター・広告デザイン（テキスト含む）
- 複雑な構図のイラスト
- プロフェッショナルなコンテンツ制作

**セットアップ例**:
```bash
# ComfyUIでのFLUX.1 Schnell使用
cd ComfyUI/models/unet
wget https://huggingface.co/black-forest-labs/FLUX.1-schnell/resolve/main/flux1-schnell.safetensors

# 量子化版（低VRAM向け）
wget https://huggingface.co/city96/FLUX.1-schnell-gguf/resolve/main/flux1-schnell-Q4_K_S.gguf
```

---

### ⭐ Stable Diffusion XL（推奨 - バランス型）

**開発**: Stability AI
**リリース**: SDXL 1.0（2023年7月）、SD 3.5（2024年10月）

**バリエーション**:

| モデル | パラメータ | VRAM要件 | 解像度 | 特徴 |
|--------|------------|----------|--------|------|
| SDXL 1.0 | 3.5B | 8-12GB | 1024×1024 | 標準・汎用 |
| SDXL Turbo | 3.5B | 6-8GB | 1024×1024 | 超高速（1-4ステップ） |
| SD 3.5 Large | 8B | 12-16GB | 1024×1024+ | 最新・高品質 |
| SD 3.5 Medium | 2.5B | 6-10GB | 1024×1024 | 軽量版 |

**主な特徴**:
- 豊富なコミュニティリソース（LoRA、ControlNet、拡張モデル多数）
- 安定した生成品質
- 幅広いスタイル対応（写実、アニメ、アート等）
- エクスプレッショニストアートなど特定スタイルでFLUXを上回る

**推奨用途**:
- 汎用的な画像生成
- スタイル特化モデルの活用
- 既存リソース（LoRA等）の豊富な選択肢

**セットアップ例**:
```bash
# Automatic1111でのSDXL使用
cd stable-diffusion-webui/models/Stable-diffusion
wget https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors
wget https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0.safetensors
```

---

### Stable Diffusion 1.5/2.1（軽量・高速）

**開発**: Stability AI
**リリース**: SD 1.5（2022年10月）、SD 2.1（2022年12月）

**スペック**:

| モデル | パラメータ | VRAM要件 | 解像度 | 特徴 |
|--------|------------|----------|--------|------|
| SD 1.5 | 0.9B | 4-6GB | 512×512 | 最軽量・最速 |
| SD 2.1 | 0.9B | 6-8GB | 768×768 | 改良版 |

**主な特徴**:
- 最も軽量で低スペックGPUでも動作
- 豊富なファインチューニングモデル（Realistic Vision、Anything等）
- AnimateDiff等のビデオ生成拡張のベース
- Raspberry Pi 4でも動作可能（非常に遅い）

**推奨用途**:
- 低スペック環境での画像生成
- 大量バッチ処理（高速生成が必要な場合）
- ビデオ生成のベースモデル

---

### その他の注目モデル

#### **Playground v2.5**
- 美しいカラーパレットと構図
- 商用利用可能
- VRAM要件: 10-16GB

#### **Kandinsky 3.0**
- ロシア発のオープンソースモデル
- 独特のアートスタイル
- VRAM要件: 8-12GB

---

## 11.4 用途別モデル選択ガイド

### プロフェッショナルなデザイン作業
- **第1選択**: FLUX.1 Dev
- **第2選択**: SD 3.5 Large
- **理由**: 最高品質、テキストレンダリング、プロンプト精度

### 趣味・個人制作
- **第1選択**: SDXL 1.0 + コミュニティモデル
- **第2選択**: FLUX.1 Schnell（高速生成）
- **理由**: バランスの良い品質、豊富なリソース、無料

### 大量バッチ処理
- **第1選択**: SDXL Turbo
- **第2選択**: SD 1.5（軽量モデル）
- **理由**: 高速生成（1-4ステップ）、低VRAM

### 低スペックPC（VRAM 6-8GB）
- **第1選択**: SD 1.5/2.1
- **第2選択**: SDXL Turbo（最適化あり）
- **理由**: 低VRAM要件、安定動作

### テキスト含む画像生成
- **第1選択**: FLUX.1 Dev/Schnell
- **理由**: テキストレンダリング精度が圧倒的

### アニメ・イラスト特化
- **第1選択**: SDXL + アニメ特化LoRA/モデル
- **第2選択**: SD 1.5 + Anything V5等
- **理由**: 豊富なアニメスタイルモデル

---

## 11.5 ローカル画像生成ツール比較

### ComfyUI（推奨 - 高度なワークフロー）

**特徴**:
- ノードベースのワークフロー構築
- 最先端モデル（FLUX、SDXL、SD3.5）を最速でサポート
- 複雑な画像生成パイプラインの作成が可能
- ワークフローの共有・再利用が容易

**推奨ユーザー**:
- 高度なカスタマイズが必要なプロユーザー
- ワークフロー自動化を求める開発者
- 最新モデルをいち早く試したい人

**VRAM最適化**: 優秀（メモリ管理が効率的）

**学習曲線**: やや急（ノードベースに慣れが必要）

**セットアップ**:
```bash
git clone https://github.com/comfyanonymous/ComfyUI.git
cd ComfyUI
pip install -r requirements.txt
python main.py
# ブラウザで http://127.0.0.1:8188 にアクセス
```

---

### Automatic1111 WebUI / Forge（推奨 - 初心者フレンドリー）

**特徴**:
- 直感的なGUIインターフェース
- 豊富な拡張機能（Extension）エコシステム
- Forgeフォーク版は高速化・最適化済み（SDXL/FLUXで4-5倍高速）
- 大規模コミュニティ（StackOverflow、Reddit等でサポート豊富）

**推奨ユーザー**:
- 初心者〜中級者
- 直感的なUIを好むユーザー
- 豊富なプリセット・拡張機能を活用したい人

**VRAM最適化**: 良好（Forgeは特に優秀）

**学習曲線**: 緩やか（最も取っつきやすい）

**セットアップ（Forge版）**:
```bash
git clone https://github.com/lllyasviel/stable-diffusion-webui-forge.git
cd stable-diffusion-webui-forge
./webui.sh  # Linuxの場合
# webui-user.bat を実行（Windowsの場合）
```

---

### Fooocus（推奨 - 最も簡単）

**特徴**:
- Midjourneyライクなシンプルなインターフェース
- ワンクリックインストーラー
- 設定不要で即座に高品質画像生成
- 初心者に最適化されたデフォルト設定

**推奨ユーザー**:
- 完全初心者
- 設定に時間をかけたくない人
- Midjourneyからの移行ユーザー

**VRAM最適化**: 良好

**学習曲線**: 最も緩やか（ほぼゼロ）

**セットアップ**:
```bash
# ワンクリックインストーラーをダウンロードして実行
# Windows: run.bat
# Linux: run.sh
```

---

### InvokeAI

**特徴**:
- プロフェッショナル向けUI
- 統合されたキャンバスエディタ
- 商用利用を想定した設計

**推奨ユーザー**: プロのデザイナー、スタジオ

---

### ツール選択フローチャート

```
開始
├─ 完全初心者・すぐ使いたい → Fooocus
├─ 一般的な画像生成・初〜中級者 → Automatic1111 / Forge
├─ 高度なワークフロー・プロユーザー → ComfyUI
└─ 商用プロジェクト・スタジオ → InvokeAI
```

---

## 11.6 パフォーマンスとVRAM最適化

### 量子化によるVRAM削減

**FP16 → FP8 量子化**:
- VRAM使用量: 約50%削減
- 品質低下: ほぼなし
- 対応モデル: FLUX.1、SDXL

**GGUF量子化（4-bit/8-bit）**:
- VRAM使用量: 60-75%削減
- 品質低下: 軽微（Q4_K_S以上推奨）
- 対応: FLUX.1、SD 1.5/2.1/XL

**例**: FLUX.1 Dev（FP16: 24GB → Q4_K_S: 6-8GB）

---

### VAE Tiling（タイル処理）

- 高解像度画像生成時のVRAM削減
- 4K以上の画像でも12GB以下で生成可能
- 品質低下: ほぼなし（適切なタイルサイズ設定時）

---

### バッチ処理の最適化

**小バッチサイズ**: VRAM節約、やや遅い
**大バッチサイズ**: 高速だがVRAM大量消費

推奨バッチサイズ:
- 8GB VRAM: 1-2枚
- 12GB VRAM: 2-4枚
- 16GB VRAM: 4-8枚
- 24GB VRAM: 8-16枚

---

## 11.7 コスト比較：クラウド vs ローカル

### クラウドサービスの料金（2025年10月）

| サービス | 料金プラン | 月額コスト | 制限 |
|----------|------------|------------|------|
| Midjourney Standard | 標準 | $30 (¥4,500) | 月間15時間（約900枚） |
| Midjourney Pro | プロ | $60 (¥9,000) | 月間30時間（約1,800枚） |
| DALL-E 3 | 従量課金 | $0.04-0.08/枚 | 1024×1024: $0.04、1792×1024: $0.08 |
| Stable Diffusion Online | 標準 | $10 (¥1,500) | 月間3,000枚 |
| Leonardo.AI | 有料 | $12 (¥1,800) | 月間8,500トークン |

---

### ローカル環境の初期投資

| 構成 | 主要GPU | 初期費用（概算） | 月額コスト（電気代） | 1年総額 | 3年総額 |
|------|---------|------------------|----------------------|---------|---------|
| 最小 | RTX 4060 (8GB) | ¥40,000 | ¥300 | ¥43,600 | ¥50,800 |
| 標準 | RTX 4060 Ti (16GB) | ¥70,000 | ¥400 | ¥74,800 | ¥84,400 |
| 推奨 | RTX 4080 (16GB) | ¥180,000 | ¥600 | ¥187,200 | ¥201,600 |
| ハイエンド | RTX 4090 (24GB) | ¥350,000 | ¥800 | ¥359,600 | ¥378,800 |

---

### 損益分岐点分析

**月間1,000枚生成の場合**:

| 選択肢 | 初期費用 | 月額コスト | 1年総額 | 3年総額 |
|--------|----------|------------|---------|---------|
| Midjourney Pro | ¥0 | ¥9,000 | ¥108,000 | ¥324,000 |
| DALL-E 3 | ¥0 | ¥6,000* | ¥72,000 | ¥216,000 |
| ローカル（標準） | ¥70,000 | ¥400 | ¥74,800 | ¥84,400 |
| ローカル（推奨） | ¥180,000 | ¥600 | ¥187,200 | ¥201,600 |

*DALL-E 3: 1,000枚 × ¥6 = ¥6,000/月（1024×1024サイズ）

**結論**:
- **1年以内で損益分岐**: 標準構成（RTX 4060 Ti 16GB）
- **2年以内で損益分岐**: 推奨構成（RTX 4080 16GB）
- 月間1,000枚以上生成する場合、ローカル環境が圧倒的にコスト効率が良い

---

### 月間5,000枚生成の場合（ヘビーユーザー）

| 選択肢 | 月額コスト | 1年総額 | 3年総額 |
|--------|------------|---------|---------|
| Midjourney Pro | ¥9,000* | ¥108,000 | ¥324,000 |
| DALL-E 3 | ¥30,000 | ¥360,000 | ¥1,080,000 |
| ローカル（推奨） | ¥600 | ¥187,200 | ¥201,600 |

*Midjourney Proは月間1,800枚が上限のため、5,000枚生成には複数アカウントが必要

**結論**: ヘビーユーザーの場合、ローカル環境は**1年目から大幅な節約**

---

## 11.8 推奨構成まとめ

### 初心者向け（予算重視）

**ハードウェア**:
- GPU: RTX 4060 8GB（¥40,000）
- RAM: 16GB
- ストレージ: 256GB SSD

**ソフトウェア**:
- ツール: Fooocus
- モデル: SD 1.5、SDXL Turbo

**想定コスト**: ¥40,000（初期）+ ¥300/月（電気代）

---

### 中級者向け（バランス型）

**ハードウェア**:
- GPU: RTX 4060 Ti 16GB（¥70,000）
- RAM: 32GB
- ストレージ: 512GB NVMe SSD

**ソフトウェア**:
- ツール: Automatic1111 Forge
- モデル: SDXL、FLUX.1 Schnell（量子化版）

**想定コスト**: ¥70,000（初期）+ ¥400/月（電気代）

---

### プロフェッショナル向け（品質重視）

**ハードウェア**:
- GPU: RTX 4080 16GB（¥180,000）or RTX 4090 24GB（¥350,000）
- RAM: 64GB
- ストレージ: 1TB NVMe SSD

**ソフトウェア**:
- ツール: ComfyUI
- モデル: FLUX.1 Dev（FP16）、SD 3.5 Large

**想定コスト**: ¥180,000-¥350,000（初期）+ ¥600-¥800/月（電気代）

---

## 11.9 セットアップガイド

### Step 1: Python環境の準備

```bash
# Python 3.10のインストール確認
python --version

# 仮想環境の作成（推奨）
python -m venv sdenv
source sdenv/bin/activate  # Linux/Mac
# sdenv\Scripts\activate.bat  # Windows
```

---

### Step 2: ComfyUIのインストール

```bash
git clone https://github.com/comfyanonymous/ComfyUI.git
cd ComfyUI
pip install -r requirements.txt

# モデルのダウンロード（例: FLUX.1 Schnell）
cd models/unet
wget https://huggingface.co/black-forest-labs/FLUX.1-schnell/resolve/main/flux1-schnell.safetensors

# VAEのダウンロード
cd ../vae
wget https://huggingface.co/black-forest-labs/FLUX.1-schnell/resolve/main/ae.safetensors

# 起動
cd ../..
python main.py
# ブラウザで http://127.0.0.1:8188 を開く
```

---

### Step 3: Automatic1111 Forge（初心者向け）

```bash
# Forgeのクローン
git clone https://github.com/lllyasviel/stable-diffusion-webui-forge.git
cd stable-diffusion-webui-forge

# Linuxでの起動
./webui.sh

# Windowsでの起動
# webui-user.bat をダブルクリック

# ブラウザで http://127.0.0.1:7860 を開く
```

**モデルの配置**:
```bash
# モデルを stable-diffusion-webui-forge/models/Stable-diffusion/ に配置
cd models/Stable-diffusion
wget https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors
```

---

### Step 4: Fooocus（最も簡単）

```bash
# リポジトリのクローン
git clone https://github.com/lllyasviel/Fooocus.git
cd Fooocus

# 依存関係のインストールと起動（自動）
python launch.py

# または、事前構築版をダウンロード
# https://github.com/lllyasviel/Fooocus/releases
# 解凍して run.bat（Windows）または run.sh（Linux）を実行
```

---

### トラブルシューティング

**CUDA Out of Memory エラー**:
```bash
# ComfyUIの起動引数で低VRAMモードを有効化
python main.py --lowvram

# または超低VRAMモード
python main.py --novram
```

**Automatic1111でのVRAM最適化**:
- Settings → Optimizations → "xformers" を有効化
- "Medvram" または "Lowvram" を有効化

---

## 11.10 最適なローカル画像生成モデル選択フローチャート

```
【予算はいくら？】
├─ ¥40,000以下
│  └─ GPU: RTX 4060 8GB
│     ├─ ツール: Fooocus
│     └─ モデル: SD 1.5、SDXL Turbo
│
├─ ¥70,000前後
│  └─ GPU: RTX 4060 Ti 16GB ← ★最もバランスが良い
│     ├─ ツール: Automatic1111 Forge
│     └─ モデル: SDXL、FLUX.1 Schnell（量子化）
│
├─ ¥180,000前後
│  └─ GPU: RTX 4080 16GB
│     ├─ ツール: ComfyUI
│     └─ モデル: FLUX.1 Dev、SD 3.5 Large
│
└─ ¥350,000以上
   └─ GPU: RTX 4090 24GB
      ├─ ツール: ComfyUI
      └─ モデル: FLUX.1 Dev（FP16）、全モデル対応

【用途別の選択】
├─ テキスト含む画像（ポスター等） → FLUX.1 Dev/Schnell
├─ 汎用的なイラスト・写真 → SDXL 1.0 + コミュニティモデル
├─ 大量高速生成 → SDXL Turbo、SD 1.5
├─ アニメ・イラスト特化 → SDXL + アニメLoRA
└─ プロフェッショナル品質 → FLUX.1 Dev、SD 3.5 Large

【スキルレベル別のツール選択】
├─ 完全初心者 → Fooocus
├─ 初心者〜中級者 → Automatic1111 Forge
├─ 上級者・プロ → ComfyUI
└─ 商用スタジオ → InvokeAI
```

---

## まとめ

ローカル画像生成AIは、2025年現在、**FLUX.1**と**Stable Diffusion XL**を中心に成熟したエコシステムを形成しています。

**推奨構成**:
- **初心者・予算重視**: RTX 4060 Ti 16GB + Automatic1111 Forge + SDXL
- **プロ・品質重視**: RTX 4080/4090 + ComfyUI + FLUX.1 Dev
- **最速で始めたい**: Fooocus（ワンクリック）

**コスト面**:
- 月間1,000枚以上生成する場合、**1年以内にローカル環境が有利**
- 初期投資¥70,000で、3年間で¥240,000以上の節約が可能

**品質面**:
- FLUX.1 Devは**テキストレンダリング・プロンプト精度で最高レベル**
- SDXLは**豊富なコミュニティリソース**で汎用性が高い

ローカル環境は、プライバシー、コスト、カスタマイズ性において圧倒的な優位性を持ち、2025年以降もAI画像生成の主流となるでしょう。
